# LLMs-tricks

- FlashAttention never constructs a full attention matrix for the calculations
- 
